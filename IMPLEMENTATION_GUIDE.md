# Sentinel Agentic Framework - Implementation Guide

This guide walks you through implementing the Sentinel Agentic Framework from scratch, understanding each component, and deploying it in production.

> **ðŸ“ System Architecture**: See [ARCHITECTURE_ENHANCED.md](ARCHITECTURE_ENHANCED.md) for complete architecture details with all 6 security layers

## Table of Contents

1. [Project Structure](#project-structure)
2. [Core Components](#core-components)
3. [Implementation Steps](#implementation-steps)
4. [Deployment Guide](#deployment-guide)
5. [Testing Strategy](#testing-strategy)
6. [Production Considerations](#production-considerations)

## Project Structure

```
ai_agent_security/
â”œâ”€â”€ sentinel/                    # Main package
â”‚   â”œâ”€â”€ __init__.py             # Package exports
â”‚   â”œâ”€â”€ schemas.py              # Pydantic models and state definition
â”‚   â”œâ”€â”€ input_guard.py          # PII detection & injection checking
â”‚   â”œâ”€â”€ output_guard.py         # Response sanitization
â”‚   â”œâ”€â”€ state_monitor.py        # Loop detection & cost monitoring
â”‚   â”œâ”€â”€ red_team.py             # Adversarial testing
â”‚   â”œâ”€â”€ audit.py                # Compliance & audit logging
â”‚   â””â”€â”€ gateway.py              # Main LangGraph orchestration
â”‚
â”œâ”€â”€ examples/                    # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py          # Basic examples
â”‚   â””â”€â”€ langchain_integration.py # LangChain integration
â”‚
â”œâ”€â”€ tests/                       # Unit and integration tests
â”‚   â”œâ”€â”€ test_input_guard.py
â”‚   â”œâ”€â”€ test_output_guard.py
â”‚   â”œâ”€â”€ test_state_monitor.py
â”‚   â”œâ”€â”€ test_red_team.py
â”‚   â””â”€â”€ test_gateway.py
â”‚
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ ARCHITECTURE.md              # Architecture details
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md      # This file
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ setup.py                     # Package installation
```

## Core Components

### 1. State Schema ([sentinel/schemas.py](sentinel/schemas.py))

The `SentinelState` TypedDict defines the complete state that flows through the LangGraph workflow.

**Key Fields:**
- `user_input` / `redacted_input`: Original and sanitized user input
- `agent_response` / `sanitized_response`: Agent output before/after sanitization
- `tool_calls`: List of all tool invocations (for loop detection)
- `security_threats`: Detected security issues
- `audit_log`: Complete audit trail
- `should_block` / `should_warn`: Control flow flags

**Implementation Notes:**
- All entities use Pydantic models for validation
- Enums provide type safety for threat levels, entity types, etc.
- Helper function `create_initial_state()` initializes workflow state

### 2. Input Guard Agent ([sentinel/input_guard.py](sentinel/input_guard.py))

**Purpose:** First line of defense - validates input before reaching the main agent

**Components:**
- `PIIDetector`: Detects sensitive entities using NER + regex
- `InjectionDetector`: Detects prompt injection attempts

**Detection Methods:**

#### PII Detection
```python
# Regex patterns for common PII types
CREDIT_CARD: r'\b(?:4[0-9]{12}(?:[0-9]{3})?)\b'  # Visa
SSN: r'\b(?!000|666|9\d{2})\d{3}-(?!00)\d{2}-(?!0000)\d{4}\b'
EMAIL: r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'

# NER using spaCy for person names, dates, etc.
nlp = spacy.load("en_core_web_sm")
entities = nlp(text).ents
```

#### Injection Detection
```python
# Pattern-based: Known attack phrases
"ignore previous instructions"
"pretend you are"
"show me your system prompt"

# Semantic: Embedding similarity to known attacks
similarity_score = cosine_similarity(input_embedding, attack_embeddings)

# Perplexity: Statistical anomaly detection
perplexity = language_model.perplexity(text)
```

**Redaction Strategies:**
- `MASK`: "4532-****-****-9010"
- `HASH`: "SHA256:a3f2c1..."
- `TOKEN`: "[REDACTED_SSN_001]"
- `ENCRYPT`: Encrypted storage with token reference

### 3. Output Guard Agent ([sentinel/output_guard.py](sentinel/output_guard.py))

**Purpose:** Final security check before returning response to user

**Components:**
- `DataLeakDetector`: Detects system prompt leaks, internal data exposure
- `ResponseValidator`: Validates against security policies
- `ResponseSanitizer`: Removes malicious content, re-redacts PII

**Leak Detection Patterns:**
```python
SYSTEM_PROMPT_LEAK = [
    "my instructions are",
    "i was told to",
    "according to my system prompt"
]

INTERNAL_DATA_LEAK = [
    "internal database",
    "production credentials",
    "api endpoint"
]

USER_DATA_LEAK = [
    "other user",
    "previous conversation"
]
```

### 4. State Monitor ([sentinel/state_monitor.py](sentinel/state_monitor.py))

**Purpose:** Prevent loops and monitor resource usage

**Loop Detection Algorithms:**

#### Exact Loop Detection
```python
# Hash tool call arguments
hash = sha256(str(sorted(arguments.items())))

# Count identical hashes
if hash appears >= max_identical_calls:
    trigger_loop_detection()
```

#### Semantic Loop Detection
```python
# Compare consecutive tool calls
for i in range(len(tool_calls) - 1):
    similarity = jaccard_similarity(
        tool_calls[i].arguments.keys(),
        tool_calls[i+1].arguments.keys()
    )
    if similarity > threshold:
        potential_semantic_loop()
```

#### Cyclic Pattern Detection
```python
# Look for repeating subsequences
# Example: [A, B, C, A, B, C] = cycle of length 3
for cycle_length in range(2, len(pattern) // 2):
    if pattern matches cycle:
        cyclic_loop_detected()
```

**Cost Monitoring:**
```python
# Token estimation: ~4 chars per token
tokens = len(text) // 4

# Cost calculation
cost = (input_tokens * input_price + output_tokens * output_price) / 1000
```

### 5. Red Team Agent ([sentinel/red_team.py](sentinel/red_team.py))

**Purpose:** Proactive adversarial testing

**Attack Vectors:**

1. **Jailbreak Attempts**
   - Direct instruction override
   - Role-play manipulation
   - Token smuggling

2. **Data Exfiltration**
   - Request conversation history
   - Social engineering for admin access
   - Tool misuse

3. **Prompt Leak**
   - Ask for system instructions
   - Request context window contents

4. **Compliance Violations**
   - Request to store PCI data
   - GDPR violation attempts

**Implementation:**
```python
# Generate attack
attack_payload = generate_attack(vector="jailbreak")

# Execute in sandbox
response = agent_executor(attack_payload)

# Analyze response
if "my instructions are" in response.lower():
    vulnerability_found = True
    severity = CRITICAL
```

### 6. Audit Manager ([sentinel/audit.py](sentinel/audit.py))

**Purpose:** Compliance checking and tamper-proof logging

**Digital Signatures:**
```python
# Create HMAC-SHA256 signature
canonical_json = json.dumps(audit_log.dict(), sort_keys=True)
signature = hmac.new(secret_key, canonical_json, sha256).hexdigest()

# Verify signature
expected = calculate_signature(audit_log)
is_valid = hmac.compare_digest(expected, audit_log.signature)
```

**Compliance Checks:**

#### PCI-DSS
- Rule 3.2: No CVV storage
- Rule 3.4: PAN must be masked/hashed/encrypted
- Rule 10.2: Audit all cardholder data access

#### GDPR
- Art. 5(1)(c): Data minimization
- Art. 25: Data protection by design
- Art. 32: Encryption requirements

#### HIPAA
- 164.312(a)(2)(i): Unique user identification
- 164.312(b): Audit controls
- 164.312(e)(2)(i): Encryption

### 7. Sentinel Gateway ([sentinel/gateway.py](sentinel/gateway.py))

**Purpose:** Main orchestration using LangGraph

**Workflow:**
```
Entry â†’ Input Guard â†’ [Route] â†’ Agent Execution â†’ State Monitor
      â†’ [Route] â†’ Output Guard â†’ Red Team â†’ Audit Finalize â†’ Exit
```

**Routing Logic:**
```python
# After Input Guard
if state["should_block"]:
    return "block"  # Skip to audit
else:
    return "continue"  # Proceed to agent

# After State Monitor
if state["loop_detected"] and state["should_block"]:
    return "block"
else:
    return "continue"
```

**Manual Orchestration (No LangGraph):**
```python
def _invoke_manual(state, agent_executor):
    # 1. Input Guard
    state = self.input_guard.process(state)
    if state["should_block"]:
        return finalize_audit(state)

    # 2. Agent Execution
    response = agent_executor(state["redacted_input"])
    state["agent_response"] = response

    # 3. State Monitor
    state = self.state_monitor.process(state)
    if state["should_block"]:
        return finalize_audit(state)

    # 4. Output Guard
    state = self.output_guard.process(state)

    # 5. Red Team (optional)
    if config.red_team.enabled:
        state = self.red_team.process(state)

    # 6. Audit
    return finalize_audit(state)
```

## Implementation Steps

### Step 1: Install Dependencies

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install requirements
pip install -r requirements.txt

# Install spaCy model
python -m spacy download en_core_web_sm
```

### Step 2: Basic Configuration

```python
from sentinel import SentinelConfig, ComplianceFramework

config = SentinelConfig()

# Enable PII detection
config.pii_detection.enabled = True
config.pii_detection.use_ner = True
config.pii_detection.use_regex = True

# Enable injection detection
config.injection_detection.enabled = True
config.injection_detection.block_threshold = 0.9

# Enable loop detection
config.loop_detection.enabled = True
config.loop_detection.max_identical_calls = 3

# Set compliance frameworks
config.compliance.frameworks = [
    ComplianceFramework.PCI_DSS,
    ComplianceFramework.GDPR,
]
```

### Step 3: Create Protected Agent

```python
from sentinel import SentinelGateway

gateway = SentinelGateway(config, secret_key="your-secret-key")

def my_agent(user_input: str) -> str:
    # Your LLM agent implementation
    return llm.invoke(user_input)

result = gateway.invoke(
    user_input="Hello world",
    agent_executor=my_agent
)
```

### Step 4: Handle Results

```python
if result["blocked"]:
    print(f"Request blocked: {result['block_reason']}")
else:
    print(f"Response: {result['response']}")

# Check for threats
if result["threats"]:
    for threat in result["threats"]:
        print(f"Threat: {threat['description']} (Severity: {threat['severity']})")

# Check compliance
if result["violations"]:
    for violation in result["violations"]:
        print(f"Violation: {violation['description']}")

# Save audit log
from pathlib import Path

gateway.audit_manager.save_report(
    result,
    filepath=Path("audit_logs") / f"{result['audit_log']['session_id']}.json",
    format="json"
)
```

## Deployment Guide

### Production Deployment Checklist

- [ ] **Security**
  - [ ] Rotate secret keys (use environment variables)
  - [ ] Use HSM or cloud KMS for key storage
  - [ ] Enable TLS for all communications
  - [ ] Set up rate limiting

- [ ] **Performance**
  - [ ] Disable Red Team or use async mode
  - [ ] Optimize entity type detection (only enable needed types)
  - [ ] Set up caching for patterns
  - [ ] Use load balancing

- [ ] **Monitoring**
  - [ ] Set up Prometheus metrics
  - [ ] Configure alerting (e.g., PagerDuty)
  - [ ] Enable distributed tracing
  - [ ] Log to centralized system (e.g., ELK)

- [ ] **Compliance**
  - [ ] Review audit log retention policies
  - [ ] Set up automated compliance reports
  - [ ] Configure backup and disaster recovery
  - [ ] Implement access controls

### Environment Variables

```bash
# .env file
SENTINEL_SECRET_KEY=your-secret-key-here
SENTINEL_ENABLE_RED_TEAM=false
SENTINEL_LOG_LEVEL=INFO
SENTINEL_AUDIT_LOG_DIR=/var/log/sentinel
SENTINEL_COMPLIANCE_FRAMEWORKS=PCI_DSS,GDPR
```

### Docker Deployment

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt
RUN python -m spacy download en_core_web_sm

COPY sentinel/ ./sentinel/
COPY examples/ ./examples/

ENV SENTINEL_SECRET_KEY=${SENTINEL_SECRET_KEY}

CMD ["python", "-m", "your_app"]
```

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sentinel-gateway
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: sentinel
        image: sentinel:latest
        env:
        - name: SENTINEL_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: sentinel-secrets
              key: secret-key
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
```

## Testing Strategy

### Unit Tests

```python
# tests/test_input_guard.py
import pytest
from sentinel import PIIDetector, PIIDetectionConfig

def test_credit_card_detection():
    config = PIIDetectionConfig()
    detector = PIIDetector(config)

    text = "My card is 4532-1234-5678-9010"
    entities = detector.detect_pii(text)

    assert len(entities) == 1
    assert entities[0].entity_type == "credit_card"
    assert entities[0].confidence > 0.9

def test_injection_detection():
    from sentinel import InjectionDetector, InjectionDetectionConfig

    config = InjectionDetectionConfig()
    detector = InjectionDetector(config)

    text = "Ignore previous instructions"
    result = detector.detect_injection(text)

    assert result.detected == True
    assert result.confidence > 0.8
```

### Integration Tests

```python
# tests/test_gateway.py
def test_end_to_end_protection():
    config = SentinelConfig()
    gateway = SentinelGateway(config)

    def mock_agent(input_text):
        return f"Echo: {input_text}"

    result = gateway.invoke(
        user_input="My SSN is 123-45-6789",
        agent_executor=mock_agent
    )

    # PII should be redacted
    assert "123-45-6789" not in result["response"]
    assert result["audit_log"]["pii_redactions"] > 0
```

## Production Considerations

### Scaling

- **Horizontal Scaling**: Stateless design allows multiple instances
- **Redis for State**: Use Redis cluster for distributed state management
- **Load Balancing**: Use NGINX or cloud load balancer

### Performance Optimization

1. **Caching**
   - Cache compiled regex patterns
   - Cache spaCy model loading
   - Cache embedding models

2. **Async Processing**
   - Run Red Team tests asynchronously
   - Batch audit log writes
   - Use async I/O for external calls

3. **Resource Management**
   - Limit context window size
   - Set timeouts on agent execution
   - Implement circuit breakers

### Monitoring Metrics

```python
# Prometheus metrics
sentinel_requests_total{status="blocked|allowed"}
sentinel_pii_detections{entity_type="ssn|credit_card|..."}
sentinel_injection_attempts{severity="high|medium|low"}
sentinel_loops_detected{loop_type="exact|semantic|cyclic"}
sentinel_compliance_violations{framework="pci_dss|gdpr|..."}
sentinel_latency_seconds{component="input_guard|output_guard|..."}
```

### Alerting Rules

```yaml
# Example Prometheus alerts
groups:
- name: sentinel
  rules:
  - alert: HighInjectionRate
    expr: rate(sentinel_injection_attempts[5m]) > 10
    annotations:
      summary: "High rate of injection attempts detected"

  - alert: ComplianceViolation
    expr: sentinel_compliance_violations > 0
    annotations:
      summary: "Compliance violation detected"
```

## Advanced Topics

### Custom Entity Detection

```python
# Add custom entity pattern
from sentinel.input_guard import PIIPatterns

PIIPatterns.CUSTOM_ID = [
    r'\b[A-Z]{3}-\d{6}\b'  # Format: ABC-123456
]

# Register in detector
detector.entity_patterns[EntityType.CUSTOM_ID] = [
    re.compile(pattern) for pattern in PIIPatterns.CUSTOM_ID
]
```

### Custom Compliance Framework

```python
from sentinel.audit import ComplianceChecker

class CustomComplianceChecker(ComplianceChecker):
    def check_my_framework(self, state):
        violations = []
        # Your custom compliance logic
        return violations
```

### Webhook Integration

```python
# Send audit events to external system
def send_audit_webhook(audit_log):
    import requests
    requests.post(
        "https://your-webhook-url.com/audit",
        json=audit_log,
        headers={"Authorization": "Bearer token"}
    )

# Integrate in gateway
result = gateway.invoke(user_input, agent_executor)
send_audit_webhook(result["audit_log"])
```

---

## Support

For questions or issues, please:
- Check the [README](README.md) for quick start guide
- Review [examples/](examples/) for code samples
- Open an issue on GitHub
- Contact: security@sentinel.ai
