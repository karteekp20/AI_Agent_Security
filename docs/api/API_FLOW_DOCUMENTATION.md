# ğŸ“Š POST /process API - Complete Flow Documentation

## Overview

The `/process` endpoint is the main entry point for all security operations. It orchestrates a multi-layer security system that protects AI agents from threats.

---

## ğŸš€ QUICK REFERENCE - Starting Points

### Main Entry Point (HTTP Layer)
**File:** `sentinel/api/server.py`  
**Line:** 290-460  
**Endpoint:** `POST /process`  
**Handler Function:** `async def process_input(req: ProcessRequest, request: Request, ...)`

---

## ğŸ“ COMPLETE REQUEST FLOW

### Step 1: HTTP Request Arrives
```
HTTP POST /process
â”œâ”€ Headers:
â”‚  â”œâ”€ X-API-Key: sk_live_xxxxx
â”‚  â”œâ”€ Content-Type: application/json
â”‚  â””â”€ [Other headers]
â””â”€ Body:
   {
     "user_input": "My credit card is 4532-1234-5678-9010",
     "user_id": "user_123",
     "session_id": "sess_abc",
     "ip_address": "192.168.1.1",
     "metadata": {}
   }
```

---

## ğŸ”„ DETAILED REQUEST-RESPONSE FLOW

```
REQUEST ARRIVES
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Request Validation (server.py:291-356)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Parse ProcessRequest model                               â”‚
â”‚ â€¢ Extract X-API-Key from headers (line 313)               â”‚
â”‚ â€¢ Validate API key against database (line 323-329)        â”‚
â”‚ â€¢ Extract org_id and workspace_id from key                â”‚
â”‚ â€¢ Get client IP address (line 334)                        â”‚
â”‚ â€¢ Log incoming request                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Rate Limiting (server.py:331-345)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ app.state.rate_limiter.check_rate_limit()                 â”‚
â”‚ â€¢ Check per-user rate limit                               â”‚
â”‚ â€¢ Check per-IP rate limit                                 â”‚
â”‚ â€¢ Return 429 if exceeded                                  â”‚
â”‚ Location: sentinel/resilience/rate_limiter.py             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    ALLOWED? â”€â”€â”€NOâ”€â”€â†’ HTTPException(429) â†’ Return to client
    â”‚ YES
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Create Initial State (server.py:347-358)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ create_initial_state(user_input, config, ...)             â”‚
â”‚ â€¢ Initialize empty security state                         â”‚
â”‚ â€¢ Generate or use provided session_id                     â”‚
â”‚ â€¢ Set request context (user_id, ip_address, etc)         â”‚
â”‚ â€¢ Create empty threat list                                â”‚
â”‚ â€¢ Initialize audit log                                    â”‚
â”‚ Location: sentinel/schemas.py:create_initial_state()      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Initialize Demo Agent (server.py:360-379)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ def demo_agent(redacted_input: str) -> str:              â”‚
â”‚ â€¢ This is the AI agent being protected                    â”‚
â”‚ â€¢ Takes redacted input (PII removed)                      â”‚
â”‚ â€¢ Returns response                                        â”‚
â”‚ â€¢ In production: Your real LLM/AI agent                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Start Tracing (server.py:381-396)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if app.state.tracer:                                      â”‚
â”‚   with app.state.tracer.trace_request(...):              â”‚
â”‚     result = app.state.gateway.invoke(...)               â”‚
â”‚                                                           â”‚
â”‚ Location: sentinel/observability/tracing.py               â”‚
â”‚ Exports to: OpenTelemetry (Jaeger, Zipkin, etc)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Main Gateway Invocation (gateway.py:553-596)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ app.state.gateway.invoke(user_input, agent_executor)     â”‚
â”‚                                                           â”‚
â”‚ Returns:                                                  â”‚
â”‚ {                                                         â”‚
â”‚   "response": "...",                                      â”‚
â”‚   "blocked": bool,                                        â”‚
â”‚   "threats": [...],                                       â”‚
â”‚   "audit_log": {...},                                     â”‚
â”‚   "risk_scores": [...],                                   â”‚
â”‚   "aggregated_risk": {...},                               â”‚
â”‚   "warnings": "..."                                       â”‚
â”‚ }                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
```

---

## ğŸ” GATEWAY INVOKE - DETAILED LAYER BREAKDOWN

### Gateway Flow (gateway.py:553-596)

```
gateway.invoke(user_input, agent_executor)
    â†“
    Check if LangGraph available? (line 577)
    â”‚
    â”œâ”€ YES â†’ _invoke_with_langgraph()
    â””â”€ NO  â†’ _invoke_manual()
    â†“
```

### Scenario A: Using LangGraph (Lines 598-644)

```
_invoke_with_langgraph(state, agent_executor)
    â†“
    graph.invoke(state)  â† Executes LangGraph workflow
    â†“
    Returns modified state
```

### Scenario B: Manual Orchestration (Lines 646-700+)

This is the more common path. It runs through each security layer sequentially:

```
_invoke_manual(state, agent_executor)
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 1: INPUT GUARD (Line 160-175)        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self.input_guard.process(state)    â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ PII Detection                            â”‚
    â”‚ â€¢ Redaction (credit cards, SSN, etc)      â”‚
    â”‚ â€¢ Prompt Injection Detection               â”‚
    â”‚ â€¢ Content Moderation (toxicity)            â”‚
    â”‚ â€¢ Risk Scoring                             â”‚
    â”‚ â€¢ Audit Event Creation                     â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/input_guard.py:757      â”‚
    â”‚ Time: ~50-100ms (with spaCy)              â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â”œâ”€ redacted_input (PII removed)            â”‚
    â”‚ â”œâ”€ original_entities (found PII)           â”‚
    â”‚ â”œâ”€ injection_detected                      â”‚
    â”‚ â”œâ”€ should_block (if threats)              â”‚
    â”‚ â”œâ”€ security_threats[]                      â”‚
    â”‚ â””â”€ risk_scores[]                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DECISION: Should Block? (Check routing)    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ if state["should_block"]:                  â”‚
    â”‚   â†’ Jump to STEP 10 (Return blocked)       â”‚
    â”‚ else:                                       â”‚
    â”‚   â†’ Continue to next layer                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 2: STATE MONITOR (Line 208-213)      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self.state_monitor.process(state)  â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Loop Detection (semantic similarity)     â”‚
    â”‚ â€¢ Cost Tracking (tokens used)              â”‚
    â”‚ â€¢ Resource Monitoring                      â”‚
    â”‚ â€¢ Budget Enforcement                       â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/state_monitor.py        â”‚
    â”‚ Time: ~10ms                                â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â”œâ”€ loop_detected                           â”‚
    â”‚ â”œâ”€ cost_metrics                            â”‚
    â”‚ â””â”€ risk_scores[] (adds state monitor risk) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 3: AGENT EXECUTION (Line 177-206)   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ def _agent_execution_node(state):           â”‚
    â”‚   response = agent_executor(state["redacted_input"])
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Calls your AI agent with redacted input â”‚
    â”‚ â€¢ Agent never sees original PII            â”‚
    â”‚ â€¢ Captures response                        â”‚
    â”‚ â€¢ Records execution in audit log           â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/gateway.py:177          â”‚
    â”‚ Time: Variable (depends on your agent)     â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â”œâ”€ agent_response                          â”‚
    â”‚ â”œâ”€ tool_calls[]                            â”‚
    â”‚ â””â”€ audit_log events                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 4: OUTPUT GUARD (Line 215-221)      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self.output_guard.process(state)   â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Re-check for PII in response             â”‚
    â”‚ â€¢ Detect data leaks                        â”‚
    â”‚ â€¢ Check for injected code                  â”‚
    â”‚ â€¢ Sanitize response                        â”‚
    â”‚ â€¢ Risk scoring                             â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/output_guard.py:233     â”‚
    â”‚ Time: ~30-50ms                             â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â”œâ”€ sanitized_response                      â”‚
    â”‚ â”œâ”€ response_pii_detected                   â”‚
    â”‚ â””â”€ risk_scores[] (adds output guard risk) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ AGGREGATION: Risk Scoring (Line 427-547)  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self._aggregate_risk_scores(state) â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Combines risk scores from all layers     â”‚
    â”‚ â€¢ Weighted calculation:                    â”‚
    â”‚   â”œâ”€ Input guard risk (40%)                â”‚
    â”‚   â”œâ”€ State monitor risk (30%)              â”‚
    â”‚   â””â”€ Output guard risk (30%)               â”‚
    â”‚ â€¢ Determines overall risk level            â”‚
    â”‚ â€¢ Decides if shadow agents escalate       â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/gateway.py:427          â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â”œâ”€ aggregated_risk {}                      â”‚
    â”‚ â”œâ”€ overall_risk_score (0.0-1.0)           â”‚
    â”‚ â”œâ”€ overall_risk_level                      â”‚
    â”‚ â””â”€ shadow_agent_escalated                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PHASE 2: SHADOW AGENTS (If escalated)     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ if state["shadow_agent_escalated"]:       â”‚
    â”‚                                             â”‚
    â”‚   â†’ Shadow Input Analysis (Line 284-331)  â”‚
    â”‚     _shadow_input_analysis_node(state)    â”‚
    â”‚     â€¢ Deep intent analysis                 â”‚
    â”‚     â€¢ LLM-based threat detection           â”‚
    â”‚                                             â”‚
    â”‚   â†’ Shadow State Analysis (Line 333-380)  â”‚
    â”‚     _shadow_state_analysis_node(state)    â”‚
    â”‚     â€¢ Behavioral analysis                  â”‚
    â”‚     â€¢ Execution pattern detection          â”‚
    â”‚                                             â”‚
    â”‚   â†’ Shadow Output Analysis (Line 382-421) â”‚
    â”‚     _shadow_output_analysis_node(state)   â”‚
    â”‚     â€¢ Response content analysis            â”‚
    â”‚     â€¢ Data leak detection                  â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/shadow_agents/         â”‚
    â”‚ Time: ~500ms-2s (LLM-based, can be async) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 5: RED TEAM (Optional/Async)        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self.red_team.process(state)      â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Adversarial testing                      â”‚
    â”‚ â€¢ Jailbreak attempts                       â”‚
    â”‚ â€¢ Vulnerability scanning                   â”‚
    â”‚ â€¢ Normally runs async                      â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/red_team.py             â”‚
    â”‚ Time: Variable (typically async)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LAYER 6: AUDIT FINALIZATION (Line 232-234)â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ state = self.audit_manager.finalize_audit  â”‚
    â”‚                                             â”‚
    â”‚ What it does:                              â”‚
    â”‚ â€¢ Complete audit log                       â”‚
    â”‚ â€¢ Digital signature (HMAC-SHA256)          â”‚
    â”‚ â€¢ Tamper-proof evidence                    â”‚
    â”‚ â€¢ Compliance report generation             â”‚
    â”‚                                             â”‚
    â”‚ Location: sentinel/audit.py                â”‚
    â”‚ Time: ~5ms                                 â”‚
    â”‚                                             â”‚
    â”‚ Output State Updates:                       â”‚
    â”‚ â””â”€ audit_log (complete & signed)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    Return modified state
```

---

## ğŸ“¤ RESPONSE BUILDING (server.py:398-440)

```
After gateway.invoke() returns:
    â†“
    Collect Metrics (if enabled)
    â”œâ”€ Total requests processed
    â”œâ”€ Blocks by layer
    â”œâ”€ PII detections
    â”œâ”€ Processing time
    â””â”€ Location: sentinel/observability/metrics.py
    â†“
    Build ProcessResponse object:
    {
      "allowed": !state["should_block"],
      "redacted_input": state["redacted_input"],
      "risk_score": state["aggregated_risk"]["overall_risk_score"],
      "risk_level": state["aggregated_risk"]["overall_risk_level"],
      "blocked": state["should_block"],
      "block_reason": state["block_reason"] if blocked else None,
      "pii_detected": len(state["original_entities"]) > 0,
      "pii_count": len(state["original_entities"]),
      "injection_detected": state["injection_detected"],
      "escalated": state["shadow_agent_escalated"],
      "processing_time_ms": (time.time() - start_time) * 1000,
      "session_id": session_id
    }
    â†“
    Return JSON Response (200 OK)
```

---

## ğŸ“ FILE STRUCTURE & KEY LOCATIONS

### API Layer
```
sentinel/api/
â”œâ”€â”€ server.py (Lines 290-460)     â† Entry point
â”œâ”€â”€ config.py                       â† Configuration
â””â”€â”€ dependencies.py                 â† Authentication
```

### Gateway & Orchestration
```
sentinel/
â”œâ”€â”€ gateway.py (Lines 553-700+)     â† Main orchestration
â””â”€â”€ schemas.py                      â† State definitions
```

### Security Layers
```
sentinel/
â”œâ”€â”€ input_guard.py (Lines 757-880)  â† Layer 1
â”œâ”€â”€ state_monitor.py                 â† Layer 2
â”œâ”€â”€ output_guard.py (Lines 233+)    â† Layer 4
â”œâ”€â”€ red_team.py                      â† Layer 5
â””â”€â”€ audit.py                         â† Layer 6
```

### Advanced Features
```
sentinel/
â”œâ”€â”€ shadow_agents/                   â† Phase 2
â”‚   â”œâ”€â”€ input_analyzer.py
â”‚   â”œâ”€â”€ state_analyzer.py
â”‚   â””â”€â”€ output_analyzer.py
â”œâ”€â”€ meta_learning/                   â† Phase 3
â””â”€â”€ observability/                   â† Phase 4
    â”œâ”€â”€ metrics.py
    â”œâ”€â”€ tracing.py
    â””â”€â”€ logging.py
```

---

## ğŸ”‘ KEY VARIABLES & STATE

### Initial State (schemas.py)
```python
{
    "user_input": str,              # Original input
    "user_id": str,                 # User identifier
    "session_id": str,              # Unique session
    "request_context": dict,        # IP, metadata, etc
    
    # Layers' outputs
    "redacted_input": str,          # PII removed
    "original_entities": list,      # PII found
    "injection_detected": bool,
    "agent_response": str,          # Agent's output
    "sanitized_response": str,      # Final response
    
    # Threats & scoring
    "should_block": bool,           # Block request?
    "block_reason": str,
    "security_threats": list,       # All threats
    "risk_scores": list,            # Per-layer scores
    "aggregated_risk": dict,        # Combined risk
    
    # Audit
    "audit_log": {
        "events": list,
        "pii_redactions": int,
        "injection_attempts": int
    },
    
    # Advanced
    "shadow_agent_escalated": bool,
    "shadow_agent_analyses": list
}
```

---

## âš¡ PERFORMANCE BREAKDOWN

```
Layer 1 (Input Guard):    50-100ms   (regex + spaCy NER)
Layer 2 (State Monitor):   ~10ms     (fast checks)
Layer 3 (Agent Exec):      Variable  (your agent)
Layer 4 (Output Guard):    30-50ms   (regex + NER)
Aggregation:               ~5ms      (calculations)
Shadow Agents (async):     500ms-2s  (LLM-based, optional)
Layer 6 (Audit):           ~5ms      (signing)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL SYNCHRONOUS:         95-165ms  (typical)
WITH SHADOW AGENTS:        500ms-2s+ (if escalated)
```

---

## ğŸš¨ ERROR HANDLING

```
Rate Limit Exceeded
    â†“
    HTTPException(429) â†’ Client
    
API Key Invalid
    â†“
    Logged but continues (treats as anonymous)
    
Agent Execution Error (Line 616-619)
    â†“
    state["agent_response"] = "Error executing agent: ..."
    state["should_warn"] = True
    Continue to output guard
    
Shadow Agent Failure (Line 326-329)
    â†“
    Logged as warning
    Continue with rule-based results
    
Any Exception
    â†“
    HTTPException(500) â†’ Server error
    Logged for debugging
```

---

## ğŸ“Š REQUEST EXAMPLE

### Input
```bash
curl -X POST http://localhost:8000/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: sk_live_abc123" \
  -d '{
    "user_input": "My credit card is 4532-1234-5678-9010",
    "user_id": "user_123",
    "session_id": "sess_abc"
  }'
```

### Processing Flow Through Layers
```
1. Input Guard:
   Input: "My credit card is 4532-1234-5678-9010"
   Detection: Credit card found at position 17
   Redaction: "My credit card is [CREDIT_CARD_REDACTED]"
   Risk: HIGH (0.95)
   Decision: BLOCK (dangerous)

2. Since blocked, skip remaining layers

3. Output: Return block_reason to client
```

### Output Response
```json
{
  "allowed": false,
  "redacted_input": "My credit card is [CREDIT_CARD_REDACTED]",
  "risk_score": 0.95,
  "risk_level": "high",
  "blocked": true,
  "block_reason": "PII detected: credit_card",
  "pii_detected": true,
  "pii_count": 1,
  "injection_detected": false,
  "escalated": false,
  "processing_time_ms": 87.5,
  "session_id": "sess_abc"
}
```

---

## ğŸ” DEBUGGING TIPS

### Enable Detailed Logging
```python
# In config.py
config.log_level = "DEBUG"
config.enable_logging = True
```

### Check Audit Trail
```python
# In response:
response["audit_log"]["events"]  # All events
response["audit_log"]["pii_redactions"]  # Count
```

### Monitor Metrics
```
GET http://localhost:8000/metrics

# Prometheus format:
sentinel_requests_total{status="blocked"}
sentinel_pii_detections_total{entity_type="credit_card"}
sentinel_request_duration_seconds{endpoint="/process"}
```

### Trace With Jaeger
```
# If OpenTelemetry enabled:
http://localhost:16686  # Jaeger UI
```

---

## ğŸ“š REFERENCES

| Component | File | Lines | Function |
|-----------|------|-------|----------|
| Entry Point | server.py | 290-460 | process_input |
| Gateway | gateway.py | 553-596 | invoke |
| Manual Flow | gateway.py | 646-700+ | _invoke_manual |
| Input Guard | input_guard.py | 757-880 | InputGuardAgent.process |
| State Monitor | state_monitor.py | - | StateMonitorAgent.process |
| Output Guard | output_guard.py | 233+ | OutputGuardAgent.process |
| Risk Aggregation | gateway.py | 427-547 | _aggregate_risk_scores |
| Shadow Agents | shadow_agents/ | - | Multiple analyzers |
| Audit | audit.py | - | AuditManager |

---

**Version:** 1.0  
**Last Updated:** January 2025  
**Status:** âœ… Complete API Flow Documentation

